{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPSiot8aN7bX0OThyEhKKOW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snehithmekala/express-exercise/blob/main/VAE_transformer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nsn633UKaAPO",
        "outputId": "0078ad77-4c60-4ba6-dbbe-0e6c82d8f475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Anomaly-VAE-Transformer' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/fialle/Anomaly-VAE-Transformer.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Anomaly-VAE-Transformer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDZWa7c-bWxJ",
        "outputId": "643b023e-cfc7-4a0e-ffa6-b61a245ed6ea"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Anomaly-VAE-Transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKg0J7HhbdMM",
        "outputId": "d0a096b4-20f1-4b1b-f367-cd585f1be5ac"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'absl-py=0.15.0=pypi_0': Expected end or semicolon (after name and no valid version specifier)\n",
            "    absl-py=0.15.0=pypi_0\n",
            "           ^ (from line 4 of requirements.txt)\n",
            "Hint: = is not a valid operator. Did you mean == ?\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Anomaly-VAE-Transformer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylDVmXZEbvtU",
        "outputId": "9db9864b-5b49-4b40-bd16-ad9841051578"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Anomaly-VAE-Transformer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed 's/=/==/2; s/==pypi_0//' requirements.txt > fixed_requirements.txt\n"
      ],
      "metadata": {
        "id": "_iAzu5RKb2PM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r fixed_requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlYX-7tXb5js",
        "outputId": "f910c9dc-23fb-4ff8-ed30-6d2b15f215c1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'absl-py=0.15.0': Expected end or semicolon (after name and no valid version specifier)\n",
            "    absl-py=0.15.0\n",
            "           ^ (from line 4 of fixed_requirements.txt)\n",
            "Hint: = is not a valid operator. Did you mean == ?\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -E 's/([a-zA-Z0-9_-]+)=([0-9])/\\1==\\2/g; s/==pypi_0//g; s/==conda_forge//g' requirements.txt > pip_requirements.txt\n"
      ],
      "metadata": {
        "id": "fwGh2NbmcKo3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head pip_requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cmd6_UahcM5L",
        "outputId": "9e308105-273f-40a4-f081-8afa9add176c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# This file may be used to create an environment using:\n",
            "# $ conda create --name <env> --file <this file>\n",
            "# platform: win-64\n",
            "absl-py==0.15.0=pypi_0\n",
            "astunparse==1.6.3=pypi_0\n",
            "backcall==0.2.0=pyh9f0ad1d_0\n",
            "backports==1.0=pyhd8ed1ab_3\n",
            "backports.functools_lru_cache==1.6.4=pyhd8ed1ab_0\n",
            "blas==1.0=mkl\n",
            "bottleneck==1.3.5=py37h080aedc_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r pip_requirements.txt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jN1n7KC3cQlX",
        "outputId": "3990e2d6-0c60-4e49-8012-904a52d8f4eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Invalid requirement: 'absl-py==0.15.0=pypi_0': Expected end or semicolon (after version specifier)\n",
            "    absl-py==0.15.0=pypi_0\n",
            "           ~~~~~~~~^ (from line 4 of pip_requirements.txt)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio\n",
        "!pip install numpy pandas matplotlib seaborn scikit-learn tqdm absl-py einops\n",
        "!pip install tensorflow tensorboard\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRRNjA6Zcqo9",
        "outputId": "df7a042e-a9bc-4c14-a31b-bd0c7adac356"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (1.4.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (0.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Dense, LSTM, RepeatVector, TimeDistributed\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "class TimeVAE:\n",
        "    def __init__(self, timesteps, features, latent_dim=16, hidden_dim=64):\n",
        "        self.timesteps = timesteps\n",
        "        self.features = features\n",
        "        self.latent_dim = latent_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.encoder = self._get_encoder()\n",
        "        self.decoder = self._get_decoder()\n",
        "\n",
        "        inputs = Input(shape=(timesteps, features))\n",
        "        z_mean, z_log_var, z = self.encoder(inputs)\n",
        "        reconstructed = self.decoder(z)\n",
        "        self.model = Model(inputs, reconstructed)\n",
        "\n",
        "        # VAE Loss\n",
        "        reconstruction_loss = tf.reduce_mean(tf.square(inputs - reconstructed))\n",
        "        kl_loss = -0.5 * tf.reduce_mean(\n",
        "            1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var)\n",
        "        )\n",
        "        vae_loss = reconstruction_loss + kl_loss\n",
        "        self.model.add_loss(vae_loss)\n",
        "        self.model.compile(optimizer='adam')\n",
        "\n",
        "    # --------------------------\n",
        "    # Encoder\n",
        "    # --------------------------\n",
        "    def _get_encoder(self):\n",
        "        inputs = Input(shape=(self.timesteps, self.features))\n",
        "        x = LSTM(self.hidden_dim, activation='relu')(inputs)\n",
        "        x = Dense(self.hidden_dim, activation='relu')(x)\n",
        "\n",
        "        # fix: use shape instead of get_shape()\n",
        "        self.encoder_last_dense_dim = x.shape[-1]\n",
        "\n",
        "        z_mean = Dense(self.latent_dim, name='z_mean')(x)\n",
        "        z_log_var = Dense(self.latent_dim, name='z_log_var')(x)\n",
        "\n",
        "        def sampling(args):\n",
        "            z_mean, z_log_var = args\n",
        "            epsilon = K.random_normal(shape=(K.shape(z_mean)[0], self.latent_dim))\n",
        "            return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "        z = tf.keras.layers.Lambda(sampling, output_shape=(self.latent_dim,), name='z')([z_mean, z_log_var])\n",
        "        return Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
        "\n",
        "    # --------------------------\n",
        "    # Decoder\n",
        "    # --------------------------\n",
        "    def _get_decoder(self):\n",
        "        latent_inputs = Input(shape=(self.latent_dim,))\n",
        "        x = RepeatVector(self.timesteps)(latent_inputs)\n",
        "        x = LSTM(self.hidden_dim, activation='relu', return_sequences=True)(x)\n",
        "        outputs = TimeDistributed(Dense(self.features))(x)\n",
        "        return Model(latent_inputs, outputs, name='decoder')\n"
      ],
      "metadata": {
        "id": "Az3rmfBZzMZ_"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from TimeVAE import TimeVAE\n",
        "\n",
        "# ✅ include the required hidden_layer_sizes argument\n",
        "vae = TimeVAE(\n",
        "    timesteps=1,\n",
        "    features=64,\n",
        "    latent_dim=8,\n",
        "    hidden_layer_sizes=[128, 64]   # 👈 add this list (required argument)\n",
        ")\n",
        "\n",
        "vae.model.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "AZfYBgo3x9dJ",
        "outputId": "27ab1848-4758-4185-967e-16eb2dfd51d3"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "BaseVariationalAutoencoder.__init__() missing 2 required positional arguments: 'seq_len' and 'feat_dim'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4265836501.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ✅ include the required hidden_layer_sizes argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m vae = TimeVAE(\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtimesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/Anomaly-VAE-Transformer/code/TimeVAE.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, hidden_layer_sizes, **kwargs)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         ):\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTimeVAE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_layer_sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: BaseVariationalAutoencoder.__init__() missing 2 required positional arguments: 'seq_len' and 'feat_dim'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RRsQ5nBc9WA",
        "outputId": "884aed86-192e-4f3b-cf99-faad275471f3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "code  fixed_requirements.txt  pip_requirements.txt  requirements.txt\n",
            "fig   LICENSE\t\t      README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls code\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJxIZZ3EdKTa",
        "outputId": "841cb053-084a-458b-cd6b-e6dda0ea3179"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " analysis.ipynb\t\t    solver.py\n",
            " anomaly_score.npy\t    Testing_filled_MITM_numeric.csv\n",
            "'anomaly score_paper.png'   tf_loss.png\n",
            " anomaly_score.png\t    tf_output.npy\n",
            " case1.png\t\t    tf_train_loss.npy\n",
            " case2.png\t\t    tf_val_loss.npy\n",
            " case3.png\t\t    TimeVAE.py\n",
            " case4.png\t\t    trainer_VAE.py\n",
            " checkpoints\t\t    transformer_loss.npy\n",
            " data_loader.py\t\t    transformer_loss.png\n",
            " datasets\t\t    Transformer.py\n",
            " embed.py\t\t    utils.py\n",
            " encoded_data.npy\t    vae_base.py\n",
            " histogram.png\t\t    vae_loss.npy\n",
            " loss_test_data.npy\t    vae_loss.png\n",
            " loss_train_data.npy\t    vae_model\n",
            " main.py\t\t    VaeTransformer.yaml\n",
            " process.ipynb\t\t    visualize.ipynb\n",
            " __pycache__\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python code/train.py --dataset ECG\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3zPNe3VdNN5",
        "outputId": "e4752ade-ee31-4ac2-d4cc-a0a061177f6b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/Anomaly-VAE-Transformer/code/train.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -R\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ujo23iySdWcP",
        "outputId": "76ed5ccd-36f5-4c76-c69d-d2b7584909eb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ".:\n",
            "code  fixed_requirements.txt  pip_requirements.txt  requirements.txt\n",
            "fig   LICENSE\t\t      README.md\n",
            "\n",
            "./code:\n",
            " analysis.ipynb\t\t    solver.py\n",
            " anomaly_score.npy\t    Testing_filled_MITM_numeric.csv\n",
            "'anomaly score_paper.png'   tf_loss.png\n",
            " anomaly_score.png\t    tf_output.npy\n",
            " case1.png\t\t    tf_train_loss.npy\n",
            " case2.png\t\t    tf_val_loss.npy\n",
            " case3.png\t\t    TimeVAE.py\n",
            " case4.png\t\t    trainer_VAE.py\n",
            " checkpoints\t\t    transformer_loss.npy\n",
            " data_loader.py\t\t    transformer_loss.png\n",
            " datasets\t\t    Transformer.py\n",
            " embed.py\t\t    utils.py\n",
            " encoded_data.npy\t    vae_base.py\n",
            " histogram.png\t\t    vae_loss.npy\n",
            " loss_test_data.npy\t    vae_loss.png\n",
            " loss_train_data.npy\t    vae_model\n",
            " main.py\t\t    VaeTransformer.yaml\n",
            " process.ipynb\t\t    visualize.ipynb\n",
            " __pycache__\n",
            "\n",
            "./code/checkpoints:\n",
            "Olympus_VAE_checkpoint.pth\n",
            "\n",
            "./code/datasets:\n",
            "daily_test_label.npy  encoded_test.npy\t     hourly_test.npy\n",
            "daily_test.npy\t      encoded_train.npy      hourly_total.csv\n",
            "daily_train.npy       hourly_test_label.npy  hourly_train.npy\n",
            "\n",
            "./code/__pycache__:\n",
            "data_loader.cpython-312.pyc\t    utils.cpython-39.pyc\n",
            "data_loader.cpython-37.pyc\t    vae_base.cpython-312.pyc\n",
            "embed.cpython-312.pyc\t\t    vae_base.cpython-37.pyc\n",
            "embed.cpython-37.pyc\t\t    vae_base.cpython-38.pyc\n",
            "loss_functions.cpython-38.pyc\t    vae_base.cpython-39.pyc\n",
            "loss_functions.cpython-39.pyc\t    vae_conv_I_model.cpython-37.pyc\n",
            "preprocess_pipeline.cpython-38.pyc  vae_conv_I_model.cpython-38.pyc\n",
            "preprocess_pipeline.cpython-39.pyc  vae_conv_I_model.cpython-39.pyc\n",
            "prp.cpython-38.pyc\t\t    vae_conv_model.cpython-37.pyc\n",
            "solver.cpython-312.pyc\t\t    vae_conv_model.cpython-38.pyc\n",
            "solver.cpython-37.pyc\t\t    vae_conv_model.cpython-39.pyc\n",
            "TimeVAE.cpython-312.pyc\t\t    vae_dense_model.cpython-37.pyc\n",
            "TimeVAE.cpython-37.pyc\t\t    vae_dense_model.cpython-38.pyc\n",
            "timeVAE.cpython-39.pyc\t\t    vae_dense_model.cpython-39.pyc\n",
            "trainer_VAE.cpython-312.pyc\t    vae_model.cpython-38.pyc\n",
            "trainer_VAE.cpython-37.pyc\t    vae_wrapper.cpython-38.pyc\n",
            "Transformer.cpython-312.pyc\t    vae_wrapper.cpython-39.pyc\n",
            "Transformer.cpython-37.pyc\t    write_outputs.cpython-38.pyc\n",
            "utils.cpython-37.pyc\t\t    write_outputs.cpython-39.pyc\n",
            "utils.cpython-38.pyc\n",
            "\n",
            "./code/vae_model:\n",
            "latent_dim_128_layers_2  latent_dim_256_layers_4  latent_dim_64_layers_2\n",
            "latent_dim_128_layers_3  latent_dim_32_layers_2   latent_dim_64_layers_3\n",
            "latent_dim_128_layers_4  latent_dim_512_layers_2  latent_dim_64_layers_4\n",
            "latent_dim_256_layers_2  latent_dim_512_layers_3\n",
            "latent_dim_256_layers_3  latent_dim_512_layers_4\n",
            "\n",
            "./code/vae_model/latent_dim_128_layers_2:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_128_layers_3:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_128_layers_4:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_256_layers_2:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_256_layers_3:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_256_layers_4:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_32_layers_2:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_512_layers_2:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_512_layers_3:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_512_layers_4:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_64_layers_2:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_64_layers_3:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./code/vae_model/latent_dim_64_layers_4:\n",
            "loss.png\t      model_encoder_wts.h5  sample.png\n",
            "model_decoder_wts.h5  model_parameters.pkl  series.png\n",
            "\n",
            "./fig:\n",
            "fig10.png  fig3.jpg  fig3.png  fig3.tif  fig8.png  fig8.tif  fig9.png  fig9.tif\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg31r8IvdrU7",
        "outputId": "300b2add-41d0-41d9-9784-24986e175653"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/Anomaly-VAE-Transformer/main.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Anomaly-VAE-Transformer/code\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zi-mYyLteANj",
        "outputId": "8ae75c36-1347-4203-8ae8-31b8fe3d0d69"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Anomaly-VAE-Transformer/code\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from trainer_VAE import VAETrainer\n",
        "from solver import Solver\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "id": "Lkn5UC1xlK75"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -i 's/np\\.Inf/np.inf/g' /content/Anomaly-VAE-Transformer/code/solver.py\n"
      ],
      "metadata": {
        "id": "8gUAlGg2fTi6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "B2cuQ0wOtl91",
        "outputId": "0dd905d2-fee5-41b8-a525-3f0fc5606fcc"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a33e1b5-87da-4479-bc7c-5e32de1cd043\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9a33e1b5-87da-4479-bc7c-5e32de1cd043\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving ton-iot.csv to ton-iot (1).csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"ton-iot.csv\")\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdgczh5bhWi7",
        "outputId": "ad518492-f588-4b8c-edcb-7477e0c6c964"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           ts         src_ip  src_port         dst_ip  dst_port proto service  \\\n",
            "0  1554198358    3.122.49.24      1883  192.168.1.152     52976   tcp       -   \n",
            "1  1554198358   192.168.1.79     47260  192.168.1.255     15600   udp       -   \n",
            "2  1554198359  192.168.1.152      1880  192.168.1.152     51782   tcp       -   \n",
            "3  1554198359  192.168.1.152     34296  192.168.1.152     10502   tcp       -   \n",
            "4  1554198362  192.168.1.152     46608  192.168.1.190        53   udp     dns   \n",
            "\n",
            "       duration  src_bytes  dst_bytes  ... http_response_body_len  \\\n",
            "0  80549.530260    1762852   41933215  ...                      0   \n",
            "1      0.000000          0          0  ...                      0   \n",
            "2      0.000000          0          0  ...                      0   \n",
            "3      0.000000          0          0  ...                      0   \n",
            "4      0.000549          0        298  ...                      0   \n",
            "\n",
            "   http_status_code  http_user_agent  http_orig_mime_types  \\\n",
            "0                 0                -                     -   \n",
            "1                 0                -                     -   \n",
            "2                 0                -                     -   \n",
            "3                 0                -                     -   \n",
            "4                 0                -                     -   \n",
            "\n",
            "   http_resp_mime_types        weird_name weird_addl  weird_notice  label  \\\n",
            "0                     -  bad_TCP_checksum          -             F      0   \n",
            "1                     -                 -          -             -      0   \n",
            "2                     -  bad_TCP_checksum          -             F      0   \n",
            "3                     -                 -          -             -      0   \n",
            "4                     -  bad_UDP_checksum          -             F      0   \n",
            "\n",
            "     type  \n",
            "0  normal  \n",
            "1  normal  \n",
            "2  normal  \n",
            "3  normal  \n",
            "4  normal  \n",
            "\n",
            "[5 rows x 45 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/Anomaly-VAE-Transformer/code/checkpoints\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DAvV1ZAiAFk",
        "outputId": "9bf1b002-26ac-4e10-e7c6-8cfbcb99c68b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olympus_VAE_checkpoint.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NevePZTwmFjS",
        "outputId": "70d442c4-c734-4d92-9f46-f31092d4ed45"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " analysis.ipynb\t\t    solver.py\n",
            " anomaly_score.npy\t   'Testing_filled_MITM_numeric (1).csv'\n",
            "'anomaly score_paper.png'   Testing_filled_MITM_numeric.csv\n",
            " anomaly_score.png\t    tf_loss.png\n",
            " case1.png\t\t    tf_output.npy\n",
            " case2.png\t\t    tf_train_loss.npy\n",
            " case3.png\t\t    tf_val_loss.npy\n",
            " case4.png\t\t    TimeVAE.py\n",
            " checkpoints\t\t    trainer_VAE.py\n",
            " data_loader.py\t\t    transformer_loss.npy\n",
            " datasets\t\t    transformer_loss.png\n",
            " embed.py\t\t    Transformer.py\n",
            " encoded_data.npy\t    utils.py\n",
            " histogram.png\t\t    vae_base.py\n",
            " loss_test_data.npy\t    vae_loss.npy\n",
            " loss_train_data.npy\t    vae_loss.png\n",
            " main.py\t\t    vae_model\n",
            " process.ipynb\t\t    VaeTransformer.yaml\n",
            " __pycache__\t\t    visualize.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from trainer_VAE import VAETrainer\n",
        "from solver import Solver   # ✅ no 'code.' here\n",
        "import pandas as pd\n",
        "\n"
      ],
      "metadata": {
        "id": "ZyEWrLkQkvCR"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c769de8f",
        "outputId": "d60cc8b1-8235-4f0f-d162-830fa7c5397e"
      },
      "source": [
        "!cat solver.py"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "import numpy as np\n",
            "import os\n",
            "import time\n",
            "\n",
            "from Transformer import TransformerModel\n",
            "from data_loader import get_loader_segment\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "def adjust_learning_rate(optimizer, epoch, lr_):\n",
            "    lr_adjust = {epoch: lr_ * (0.5 ** ((epoch - 1) // 1))}\n",
            "    if epoch in lr_adjust.keys():\n",
            "        lr = lr_adjust[epoch]\n",
            "        for param_group in optimizer.param_groups:\n",
            "            param_group['lr'] = lr\n",
            "        print('Updating learning rate to {}'.format(lr))\n",
            "\n",
            "\n",
            "class EarlyStopping:\n",
            "    def __init__(self, patience=7, verbose=False, dataset_name='', delta=0):\n",
            "        self.patience = patience\n",
            "        self.verbose = verbose\n",
            "        self.counter = 0\n",
            "        self.best_score = None\n",
            "        self.best_score2 = None\n",
            "        self.early_stop = False\n",
            "        self.val_loss_min = np.inf\n",
            "        self.val_loss2_min = np.inf\n",
            "        self.delta = delta\n",
            "        self.dataset = dataset_name\n",
            "\n",
            "    def __call__(self, val_loss, val_loss2, model, path):\n",
            "        score = -val_loss\n",
            "        score2 = -val_loss2\n",
            "        if self.best_score is None:\n",
            "            self.best_score = score\n",
            "            self.best_score2 = score2\n",
            "            self.save_checkpoint(val_loss, val_loss2, model, path)\n",
            "        elif score < self.best_score + self.delta or score2 < self.best_score2 + self.delta:\n",
            "            self.counter += 1\n",
            "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
            "            if self.counter >= self.patience:\n",
            "                self.early_stop = True\n",
            "        else:\n",
            "            self.best_score = score\n",
            "            self.best_score2 = score2\n",
            "            self.save_checkpoint(val_loss, val_loss2, model, path)\n",
            "            self.counter = 0\n",
            "\n",
            "    def save_checkpoint(self, val_loss, val_loss2, model, path):\n",
            "        import torch\n",
            "\n",
            "        if self.verbose:\n",
            "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
            "        torch.save(model.state_dict(), os.path.join(path, str(self.dataset) + '_checkpoint.pth'))\n",
            "        self.val_loss_min = val_loss\n",
            "        self.val_loss2_min = val_loss2\n",
            "\n",
            "\n",
            "class Solver(object):\n",
            "    DEFAULTS = {}\n",
            "\n",
            "    def __init__(self, config):\n",
            "\n",
            "        self.__dict__.update(Solver.DEFAULTS, **config)\n",
            "        torch.cuda.empty_cache()\n",
            " \n",
            "\n",
            "        self.train_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,\n",
            "                                               mode='train', dataset=self.dataset)\n",
            "        self.vali_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,\n",
            "                                              mode='val', dataset=self.dataset)\n",
            "        self.test_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,\n",
            "                                              mode='test', dataset=self.dataset)\n",
            "        self.thre_loader = get_loader_segment(self.data_path, batch_size=self.batch_size, win_size=self.win_size,\n",
            "                                              mode='thre', dataset=self.dataset)\n",
            "\n",
            "        self.device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
            "        self.build_model()\n",
            "\n",
            "    def build_model(self):\n",
            "\n",
            "        self.model = TransformerModel(n_feature=self.input_c, d_model=512, nhead=8, d_hid=512, nlayers=3, dropout=0.2).to(self.device)\n",
            "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
            "        self.criterion = nn.MSELoss()\n",
            "        if torch.cuda.is_available():\n",
            "            self.model.cuda()\n",
            "\n",
            "    def vali(self, vali_loader):\n",
            "        self.model.eval()\n",
            "\n",
            "        crit = nn.MSELoss()\n",
            "        loss_1 = []\n",
            "        for i, (input_data, _) in enumerate(vali_loader):\n",
            "            input = input_data.float().to(self.device)\n",
            "            output = self.model(input, src_mask=None)\n",
            "            rec_loss = crit(output, input)\n",
            "            loss_1.append(rec_loss.item())  \n",
            "\n",
            "        return np.average(loss_1)\n",
            "\n",
            "    def train(self):\n",
            "\n",
            "        print(\"======================TRAIN MODE======================\")\n",
            "\n",
            "        time_now = time.time()\n",
            "        path = self.model_save_path\n",
            "        if not os.path.exists(path):\n",
            "            os.makedirs(path)\n",
            "        early_stopping = EarlyStopping(patience=3, verbose=True, dataset_name=self.dataset)\n",
            "        train_steps = len(self.train_loader)\n",
            "\n",
            "        train_losses = []\n",
            "        val_losses = []\n",
            "\n",
            "        for epoch in range(self.num_epochs):\n",
            "            iter_count = 0\n",
            "            loss1_list = []\n",
            "\n",
            "            epoch_time = time.time()\n",
            "            self.model.train()\n",
            "\n",
            "            for i, (input_data, labels) in enumerate(self.train_loader):\n",
            "                self.optimizer.zero_grad()\n",
            "                iter_count += 1\n",
            "\n",
            "                input = input_data.float().to(self.device)\n",
            "\n",
            "                output = self.model(input, src_mask=None)\n",
            "\n",
            "                loss = self.criterion(output, input)\n",
            "\n",
            "                loss1_list.append(loss.item())\n",
            "                \n",
            "                if (i + 1) % 100 == 0:\n",
            "                    speed = (time.time() - time_now) / iter_count\n",
            "                    left_time = speed * ((self.num_epochs - epoch) * train_steps - i)\n",
            "                    print('\\tspeed: {:.4f}s/iter; left time: {:.4f}s'.format(speed, left_time))\n",
            "                    iter_count = 0\n",
            "                    time_now = time.time()\n",
            "\n",
            "                loss.backward()\n",
            "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
            "\n",
            "                self.optimizer.step()\n",
            "\n",
            "            print(\"Epoch: {} cost time: {}\".format(epoch + 1, time.time() - epoch_time))\n",
            "            train_loss = np.average(loss1_list)\n",
            "\n",
            "            vali_loss = self.vali(self.vali_loader)\n",
            "            \n",
            "            train_losses.append(train_loss)\n",
            "            val_losses.append(vali_loss)\n",
            "\n",
            "            print(\n",
            "                \"Epoch: {0}, Steps: {1} | Train Loss: {2:.7f} Vali Loss: {3:.7f} \".format(\n",
            "                    epoch + 1, train_steps, train_loss, vali_loss))\n",
            "            early_stopping(vali_loss, vali_loss, self.model, path)\n",
            "            if early_stopping.early_stop:\n",
            "                print(\"Early stopping\")\n",
            "                break\n",
            "            adjust_learning_rate(self.optimizer, epoch + 1, self.lr)\n",
            "\n",
            "        np.save('tf_train_loss.npy', train_losses)\n",
            "        np.save('tf_val_loss.npy', val_losses)\n",
            "        plt.plot(train_losses)\n",
            "        plt.plot(val_losses)\n",
            "        plt.title('Training/Validation Loss of Transformer')   \n",
            "        plt.xlabel('epoch')\n",
            "        plt.ylabel('loss')\n",
            "        plt.legend(['train loss', 'validation loss'])\n",
            "        plt.grid(True)\n",
            "        plt.savefig('tf_loss.png', dpi=500)\n",
            "\n",
            "\n",
            "    def test(self):\n",
            "        self.model.load_state_dict(\n",
            "            torch.load(\n",
            "                os.path.join(str(self.model_save_path), str(self.dataset) + '_checkpoint.pth')))\n",
            "        self.model.eval()\n",
            "\n",
            "        print(\"======================TEST MODE======================\")\n",
            "\n",
            "        criterion = nn.MSELoss(reduce=False)\n",
            "\n",
            "        losses = []\n",
            "        for i, (input_data, labels) in enumerate(self.train_loader):\n",
            "            input = input_data.float().to(self.device)\n",
            "            output = self.model(input, src_mask=None)\n",
            "            loss = torch.mean(criterion(input, output), dim=-1)\n",
            "            loss = loss.detach().cpu().numpy()\n",
            "            losses.append(loss)\n",
            "\n",
            "        losses = np.concatenate(losses, axis=0)\n",
            "        train_loss = np.array(losses)\n",
            "        np.save('loss_train_data.npy', train_loss)\n",
            "\n",
            "\n",
            "        test_labels = []\n",
            "        losses = []\n",
            "        outputs = []\n",
            "        for i, (input_data, labels) in enumerate(self.test_loader):\n",
            "            input = input_data.float().to(self.device)\n",
            "            output = self.model(input, src_mask=None)\n",
            "            outputs.append(output.detach().cpu().numpy())\n",
            "\n",
            "            loss = torch.mean(criterion(input, output), dim=-1)\n",
            "\n",
            "            loss = loss.detach().cpu().numpy()\n",
            "            losses.append(loss)\n",
            "            test_labels.append(labels)\n",
            "\n",
            "        outputs = np.concatenate(outputs, axis=0)\n",
            "        np.save('tf_output.npy', outputs)\n",
            "\n",
            "        losses = np.concatenate(losses, axis=0)\n",
            "        test_loss = np.array(losses)\n",
            "        np.save('loss_test_data.npy', test_loss)\n",
            "\n",
            "        test_labels = np.concatenate(test_labels, axis=0).reshape(-1)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 40 /content/Anomaly-VAE-Transformer/code/trainer_VAE.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPqghK94lZ3u",
        "outputId": "39d67976-b8e6-49db-d572-98b534cd2e2e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "import os, warnings\n",
            "warnings.filterwarnings('ignore') \n",
            "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
            "\n",
            "import numpy as np\n",
            "import pandas as pd\n",
            "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
            "import matplotlib.pyplot as plt\n",
            "import matplotlib.cm as cm\n",
            "from TimeVAE import TimeVAE\n",
            "from tensorflow.keras.optimizers import Adam\n",
            "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
            "import joblib\n",
            "import tensorflow as tf\n",
            "#import utils\n",
            "\n",
            "\n",
            "class VAETrainer():\n",
            "    DEFAULTS = {}\n",
            "\n",
            "    def __init__(self, config):\n",
            "\n",
            "        self.__dict__.update(VAETrainer.DEFAULTS, **config)\n",
            "\n",
            "        self.data_dir = './datasets/'\n",
            "        self.train_file = 'hourly_train.npy'\n",
            "        self.test_file = 'hourly_test.npy'\n",
            "\n",
            "        self.win_size = 24\n",
            "        self.n_feature = 12\n",
            "        self.batch_size = 32\n",
            "\n",
            "        self.train, self.val, self.test = self.get_data(self.data_dir, self.train_file, self.test_file)\n",
            "\n",
            "        early_stop_loss = 'loss'\n",
            "        self.early_stop_callback = EarlyStopping(monitor=early_stop_loss, min_delta = 1e-4, patience=10) \n",
            "        self.reduceLR = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5)\n",
            "\n",
            "    def training(self, epochs=1000):\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your input data\n",
        "df = pd.read_csv(\"ton-iot.csv\")\n",
        "\n",
        "print(\"Data loaded successfully!\")\n",
        "print(df.shape)\n",
        "print(df.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxFTWguAleIC",
        "outputId": "ac309dc0-e713-4f61-e99e-6622e6a15f22"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaded successfully!\n",
            "(19, 45)\n",
            "           ts         src_ip  src_port         dst_ip  dst_port proto service  \\\n",
            "0  1554198358    3.122.49.24      1883  192.168.1.152     52976   tcp       -   \n",
            "1  1554198358   192.168.1.79     47260  192.168.1.255     15600   udp       -   \n",
            "2  1554198359  192.168.1.152      1880  192.168.1.152     51782   tcp       -   \n",
            "3  1554198359  192.168.1.152     34296  192.168.1.152     10502   tcp       -   \n",
            "4  1554198362  192.168.1.152     46608  192.168.1.190        53   udp     dns   \n",
            "\n",
            "       duration  src_bytes  dst_bytes  ... http_response_body_len  \\\n",
            "0  80549.530260    1762852   41933215  ...                      0   \n",
            "1      0.000000          0          0  ...                      0   \n",
            "2      0.000000          0          0  ...                      0   \n",
            "3      0.000000          0          0  ...                      0   \n",
            "4      0.000549          0        298  ...                      0   \n",
            "\n",
            "   http_status_code  http_user_agent  http_orig_mime_types  \\\n",
            "0                 0                -                     -   \n",
            "1                 0                -                     -   \n",
            "2                 0                -                     -   \n",
            "3                 0                -                     -   \n",
            "4                 0                -                     -   \n",
            "\n",
            "   http_resp_mime_types        weird_name weird_addl  weird_notice  label  \\\n",
            "0                     -  bad_TCP_checksum          -             F      0   \n",
            "1                     -                 -          -             -      0   \n",
            "2                     -  bad_TCP_checksum          -             F      0   \n",
            "3                     -                 -          -             -      0   \n",
            "4                     -  bad_UDP_checksum          -             F      0   \n",
            "\n",
            "     type  \n",
            "0  normal  \n",
            "1  normal  \n",
            "2  normal  \n",
            "3  normal  \n",
            "4  normal  \n",
            "\n",
            "[5 rows x 45 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Load the saved model checkpoint\n",
        "checkpoint_path = \"checkpoints/Olympus_VAE_checkpoint.pth\"\n",
        "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
        "\n",
        "print(\"Checkpoint loaded successfully!\")\n",
        "print(checkpoint.keys())  # just to inspect what’s inside\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQ5vV3cboz8w",
        "outputId": "2030a056-e214-4ad9-ead2-eda5d90225d6"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint loaded successfully!\n",
            "odict_keys(['transformer_encoder.layers.0.self_attn.in_proj_weight', 'transformer_encoder.layers.0.self_attn.in_proj_bias', 'transformer_encoder.layers.0.self_attn.out_proj.weight', 'transformer_encoder.layers.0.self_attn.out_proj.bias', 'transformer_encoder.layers.0.linear1.weight', 'transformer_encoder.layers.0.linear1.bias', 'transformer_encoder.layers.0.linear2.weight', 'transformer_encoder.layers.0.linear2.bias', 'transformer_encoder.layers.0.norm1.weight', 'transformer_encoder.layers.0.norm1.bias', 'transformer_encoder.layers.0.norm2.weight', 'transformer_encoder.layers.0.norm2.bias', 'transformer_encoder.layers.1.self_attn.in_proj_weight', 'transformer_encoder.layers.1.self_attn.in_proj_bias', 'transformer_encoder.layers.1.self_attn.out_proj.weight', 'transformer_encoder.layers.1.self_attn.out_proj.bias', 'transformer_encoder.layers.1.linear1.weight', 'transformer_encoder.layers.1.linear1.bias', 'transformer_encoder.layers.1.linear2.weight', 'transformer_encoder.layers.1.linear2.bias', 'transformer_encoder.layers.1.norm1.weight', 'transformer_encoder.layers.1.norm1.bias', 'transformer_encoder.layers.1.norm2.weight', 'transformer_encoder.layers.1.norm2.bias', 'transformer_encoder.layers.2.self_attn.in_proj_weight', 'transformer_encoder.layers.2.self_attn.in_proj_bias', 'transformer_encoder.layers.2.self_attn.out_proj.weight', 'transformer_encoder.layers.2.self_attn.out_proj.bias', 'transformer_encoder.layers.2.linear1.weight', 'transformer_encoder.layers.2.linear1.bias', 'transformer_encoder.layers.2.linear2.weight', 'transformer_encoder.layers.2.linear2.bias', 'transformer_encoder.layers.2.norm1.weight', 'transformer_encoder.layers.2.norm1.bias', 'transformer_encoder.layers.2.norm2.weight', 'transformer_encoder.layers.2.norm2.bias', 'encoder.value_embedding.tokenConv.weight', 'encoder.position_embedding.pe', 'decoder.weight', 'decoder.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from solver import Solver\n",
        "\n",
        "# ✅ Configuration expected by Solver\n",
        "config = {\n",
        "    \"batch_size\": 32,\n",
        "    \"win_size\": 24,\n",
        "    \"dataset\": \"Olympus\",\n",
        "    \"data_path\": \"/content/Anomaly-VAE-Transformer/code/datasets\",\n",
        "    \"train\": True,\n",
        "    \"test\": False,\n",
        "    \"input_c\": 64,   # Number of features in your CSV (you showed 46 columns)\n",
        "    \"lr\": 0.0001\n",
        "}\n",
        "\n",
        "# ✅ Initialize Solver safely\n",
        "solver = Solver(config)\n",
        "\n",
        "# ✅ Load checkpoint\n",
        "checkpoint_path = \"/content/Anomaly-VAE-Transformer/code/checkpoints/Olympus_VAE_checkpoint.pth\"\n",
        "model_state = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
        "\n",
        "# Load weights into correct model\n",
        "if hasattr(solver, 'vae'):\n",
        "    solver.vae.load_state_dict(model_state)\n",
        "    print(\"✅ Weights loaded into solver.vae\")\n",
        "elif hasattr(solver, 'model'):\n",
        "    solver.model.load_state_dict(model_state)\n",
        "    print(\"✅ Weights loaded into solver.model\")\n",
        "else:\n",
        "    print(\"⚠️ Model attribute not found; weights loaded as raw state_dict\")\n",
        "\n",
        "print(\"✅ Checkpoint loaded successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8GyR2JXpiNJ",
        "outputId": "221a1cc6-1a0e-4023-baa1-91373c0de286"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Weights loaded into solver.model\n",
            "✅ Checkpoint loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, pandas as pd, torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# ✅ Load your CSV file\n",
        "csv_name = \"ton-iot.csv\"   # change if needed\n",
        "df = pd.read_csv(csv_name)\n",
        "print(\"CSV loaded:\", df.shape)\n",
        "\n",
        "# ✅ Keep only numeric columns for model input\n",
        "numeric_df = df.select_dtypes(include=[np.number]).copy()\n",
        "n_features = numeric_df.shape[1]\n",
        "\n",
        "# ✅ Pad to 64 features if fewer\n",
        "if n_features < 64:\n",
        "    for i in range(64 - n_features):\n",
        "        numeric_df[f'pad_{i}'] = 0.0\n",
        "elif n_features > 64:\n",
        "    numeric_df = numeric_df.iloc[:, :64]\n",
        "print(\"Numeric features shape after padding:\", numeric_df.shape)\n",
        "\n",
        "# ✅ Prepare windowed data (default win_size = 24)\n",
        "win_size = 1\n",
        "X = numeric_df.values.astype(np.float32)\n",
        "rows = X.shape[0]\n",
        "windows = []\n",
        "for start in range(0, rows - win_size + 1):\n",
        "    w = X[start:start+win_size, :]\n",
        "    windows.append(w)\n",
        "windows = np.stack(windows, axis=0)\n",
        "print(\"Windows shape:\", windows.shape)\n",
        "\n",
        "# ✅ Convert to tensor\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tensor_data = torch.tensor(windows, dtype=torch.float32).to(device)\n",
        "loader = DataLoader(TensorDataset(tensor_data), batch_size=32, shuffle=False)\n",
        "\n",
        "# ✅ Run inference\n",
        "solver.model.eval()\n",
        "all_losses = []\n",
        "with torch.no_grad():\n",
        "    for (batch,) in loader:\n",
        "        output = solver.model(batch, src_mask=None)\n",
        "        mse = torch.mean((output - batch)**2, dim=(1,2))\n",
        "        all_losses.append(mse.cpu().numpy())\n",
        "all_losses = np.concatenate(all_losses)\n",
        "\n",
        "# ✅ Map window-level losses to row-level scores\n",
        "row_scores = np.zeros(rows)\n",
        "counts = np.zeros(rows)\n",
        "for i in range(len(all_losses)):\n",
        "    for j in range(i, i + win_size):\n",
        "        if j < rows:\n",
        "            row_scores[j] += all_losses[i]\n",
        "            counts[j] += 1\n",
        "counts[counts == 0] = 1\n",
        "row_scores = row_scores / counts\n",
        "\n",
        "# ✅ Threshold to decide Attack / Normal\n",
        "threshold = row_scores.mean() + row_scores.std()\n",
        "preds = np.where(row_scores > threshold, \"Attack\", \"Normal\")\n",
        "\n",
        "# ✅ If label column exists, compute accuracy\n",
        "label_col = None\n",
        "for name in ['label','attack','attack_type','Label']:\n",
        "    if name in df.columns:\n",
        "        label_col = name\n",
        "        break\n",
        "\n",
        "if label_col:\n",
        "    y_true = df[label_col].astype(str).str.lower()\n",
        "    y_true_bin = np.where(y_true.isin(['normal','benign','0']), 0, 1)\n",
        "    pred_bin = np.where(preds == \"Attack\", 1, 0)\n",
        "    acc = (y_true_bin == pred_bin).mean() * 100\n",
        "    print(f\"✅ Accuracy: {acc:.2f}%\")\n",
        "else:\n",
        "    print(\"⚠️ No label column found — only showing predictions.\")\n",
        "\n",
        "# ✅ Save predictions\n",
        "df['anomaly_score'] = row_scores\n",
        "df['prediction'] = preds\n",
        "df.to_csv(\"predictions_with_scores.csv\", index=False)\n",
        "print(\"✅ Saved: predictions_with_scores.csv\")\n",
        "print(df[['prediction','anomaly_score']].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ruj-6lL0rOQZ",
        "outputId": "e7166029-41f1-4079-8550-d5b57196ad29"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV loaded: (19, 45)\n",
            "Numeric features shape after padding: (19, 64)\n",
            "Windows shape: (19, 1, 64)\n",
            "✅ Accuracy: 42.11%\n",
            "✅ Saved: predictions_with_scores.csv\n",
            "  prediction  anomaly_score\n",
            "0     Normal   3.777370e+16\n",
            "1     Normal   3.774270e+16\n",
            "2     Normal   3.774270e+16\n",
            "3     Normal   3.774270e+16\n",
            "4     Normal   3.774270e+16\n",
            "5     Normal   3.774270e+16\n",
            "6     Normal   3.774270e+16\n",
            "7     Normal   3.774270e+16\n",
            "8     Normal   3.784016e+16\n",
            "9     Normal   3.784016e+16\n"
          ]
        }
      ]
    }
  ]
}